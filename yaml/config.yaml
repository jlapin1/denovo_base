eval_only: True
eval_outpath: ./
batch_size: 100
top_peaks: 100
pep_length: [0, 40]
epochs: 56

# Learning rate
lr: 0.0002
lr_warmup: False
lr_warmup_start: 1.0e-6
lr_warmup_end: 2.0e-4
lr_warmup_steps: 20000

# Loading previous weights
prev_wts: /cmnfs/proj/denovo/experiments/2025-01-30_19-11-43 # Load weights from previous run (project path->timestamp)
load_last: False

# Logging and saving weights
log_wandb: True
wandb_entity: joellapin
wandb_project: diffusion
save_weights: True
high_score: aa_recall

# Loader options
loader:
  train_dataset_path: /cmnfs/data/proteomics/foundational_model/9_species_V1
  train_name:
  val_dataset_path: /cmnfs/data/proteomics/foundational_model/9_species_V1
  val_name: saccharomyces_cerevisiae
  masses_path: /cmnfs/data/proteomics/foundational_model/MassiveKB
  dictionary_path: /cmnfs/data/proteomics/foundational_model/9_species_V1/ns_dictionary.txt
  buffer_size: 10000
  num_workers: 9
  val_steps: 100
  remove_columns:
    - 'evidence_index'
    - 'scan_number'
    - 'sequence'
    - 'precursor_mz'
    - 'retention_time'
    - 'title'
    - 'scans'
  scratch:
    use: False
    path: /media/storage/scratch/ninespecies/

# Models
encoder_name: mine # depthcharge | {other}
decoder_name:  ar # *diff* | *

# Encoder model

encoder_dict:
  norm_type: 'layer'
  mz_units: 1024
  ab_units: 256
  subdivide: False
  running_units: 512
  att_d: 64
  att_h: 8
  gate: False
  alphabet: False
  depth: 9
  ffn_multiplier: 2
  prenorm: True
  prec_type: inject_pre
  use_charge: False
  use_mass: False
  bias: # 'pairwise' | 'regular' | False | None
  dropout: 0.25
  recycling_its: 1
  pw_mz_units: 512
  pw_run_units: 64
  pw_attention_ch: 32
  pw_attention_h: 2
  pw_n: 4
  pw_blocks: 0

# Decoder model

decoder_ar:
  running_units: 512
  max_sequence_length: 100
  depth: 9
  d: 64
  h: 8
  ffn_multiplier: 2
  ce_units: 256
  use_charge: True
  use_energy: False
  use_mass: True
  prec_type: 'inject_pre' # inject_pre | inject_ffn | inject_norm | pretoken | posttoken | None
  norm_type: 'layer'
  prenorm: True
  preembed: True
  penultimate_units:
  pool: False
  dropout: 0.25
  alphabet: False

decoder_diff:
  diffusion_config:
    sequence_len: 21
    learn_sigma: False
    sigma_small: False
    sigma_weight: 1.0 # vlb_weight
    class_cond: False
    diffusion_steps: 200
    noise_schedule: mine
    timestep_respacing: ""
    use_kl: False
    predict_xstart: True
    clip_denoised: False
    rescale_timesteps: True
    rescale_learned_sigmas: True
    use_checkpoint: False
    model_arch: transformer
    in_channel: 512
    out_channel: 512
    logits_mode: 1
    training_mode: diffusion-lm
    init_pretrained: False
    freeze_embeddings: False
    use_pretrained_embeddings: True
    load_ckpt:
    loss_update_granu: 20
    schedule_update_stride: 2000000
    use_loss_mask: False
  model_config:
    running_units: 512
    sequence_length: 30
    depth: 9
    d: 64
    h: 8
    ffn_multiplier: 2
    ce_units: 256
    use_charge: True
    use_energy: False
    use_mass: True
    prec_type: None
    norm_type: 'layer'
    prenorm: True
    preembed: True
    penultimate_units:
    pool: False
    dropout: 0
    alphabet: False
    self_condition: True
    clamp_denoised: False

